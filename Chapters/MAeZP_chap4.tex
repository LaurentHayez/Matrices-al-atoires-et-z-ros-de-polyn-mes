%-----------------------------------------------------------------------%
%______//------ Matrices aléatoires et zéros de polynômes ------\\______%
%______||------                Chapitre 4                ------||______%
%______\\------  ------//______%
%-----------------------------------------------------------------------%

\chapter{Graphes de \textsc{Ramanujan}}
\label{cha:graph-de-ramanujan}

\section{Théorie algébrique des graphes}
\label{sec:theor-algebr-des-graphes}

Un \emph{\index{graphe}graphe} fini est une paire $X = (V,E)$ composé d'un ensemble $V$ de sommets (\og
vertices\fg{} en anglais) et $E \subset V \times V$ d'arêtes (\og edges\fg{} en anglais). On supposera dans le
cours qu'on a au plus une arête entre deux sommets (i.e. on n'a pas de multigraphe), qu'on n'a pas de boucle,
et on considère que les arêtes ne sont pas orientés (i.e. si $e = (v,w) \in E$, $e' = (w,v) \in E$).

On dit qu'un graphe est \emph{\index{graphe!connexe}connexe} s'il existe un chemin entre toute paire de sommet de
$V$.

On met la \index{relation d'adjacence}relation d'adjacence $x \sim y \iff \{x, y\} \in E$, et la \emph{\index{matrice
d'adjacence}matrice d'adjacence} $A$ est indexée par les paires de sommets 
\[ A_{xy} =
  \begin{cases}
    1 & \text{si } x \sim y\\
    0 & \text{si } x \not\sim y
  \end{cases}
\]

L'application linéaire correspondante $A \colon \C V \to \C V$ (où $\C V$ est l'ensemble des fonctions $f
\colon V \to \C$), qui à $f \in \C V$ associe 
\[ (A f)(x) = \sum_{y \colon y \sim x}^{}f(y). \]

Puisque $A = A^\top$, on sait par l'algèbre linéaire que le spectre de $A$ $\sigma(A)$ (l'ensemble des valeurs
propres) est réel et $A$ est diagonalisable.

On dit que $X$ est \emph{\index{graphe!$d$-régulier}$d$-régulier} si tout sommet a $d$ voisins.

On dit que $X$ est \emph{\index{graphe!biparti}biparti} ou \emph{\index{graphe!bicolorable}bicolorable} si et
seulement si $V = V_1 \sqcup V_2$ tq 
\[ x \sim y \implies
  \begin{cases}
    x \in V_1 \text{ et } y \in V_2\\
    \text{ou}\\
    x \in V_2 \text{ et } y \in V_1.
  \end{cases}
\]

\begin{prop}
  Soit $X$ un graphe $d$-régulier, connexe fini. Alors
  \begin{enumerate}
  \item si $\lambda$ est une valeur propre de $A$, alors $|\lambda| \leq d$~;
  \item $d$ est valeur propre de multiplicité $1$~;
  \item $-d$ est valeur propre de $A$ ssi $X$ est biparti (ou bicolorable), et dans ce cas $\sigma(A)$ est
    symétrique par rapport à $0$ ($\lambda \in \sigma(A) \implies -\lambda \in \sigma(A)$).
  \end{enumerate}

\end{prop}


\begin{preuve}
  \begin{enumerate}
  \item Soit $\lambda \in \sigma(A)$ et soit $f$ la fonction propre associée à $\lambda$. Soit $x_0 \in V$ tel
    que $|f(x_0)| \geq |f(x)|$ pour tout $x \in V$. On a 
    \[ |\lambda||f(x_0)| = |\lambda f(x_0)| = |Af(x_0)| = \left| \sum_{y \sim x_0}^{}f(y) \right| \leq
      \underbrace{\sum_{y\sim x_0}^{}|f(y)|}_{d \text{ termes}} \leq d|f(x_0)|,\]
    et donc (puisque $f$ est une fonction propre non nulle)
    \[ |\lambda| \leq d. \]

    
  \item Soit $f \equiv 1$ sur $V$, alors $Af = df$ et 
    \[ Af(x) = \sum_{y \sim x}^{} f(y) = d. \]
    Soit à présent $f$ la fonction propre associée à $d$. On veut montrer qu'alors $f$ est constante. On peut
    supposer $f$ à valeurs réelles (car on peut séparer parties réelles et imaginaires). Soit $x_0 \in V$ un sommet qui réalise 
    \[ |f(x_0)| \geq |f(x)|\ \forall x \in V. \]
    Quitte à remplacer $f$ par $-f$, on peut supposer que $f(x_0) > 0$. On a 
    \[ df(x_0) = Af(x_0) = \sum_{y \sim x_0}^{} f(y).  \]
    Ainsi 
    \[ f(x_0) = \frac{1}{d} \sum_{y \sim x_0}^{}f(y), \]
    i.e. on peut voir $f(x_0)$ comme la moyenne de $f$ sur les $d$ voisins. Mais puisque $f(x_0)$ est un
    maximum, on a que $f(y) = f(x_0)$ pour tout $y \sim x_0$. En continuant ainsi, par connexité, $f$ est
    constante. On voit encore que $d$ est de multiplicité $1$ car l'espace propre associé est de dimension $1$.

  \item Soit $X$ biparti. Alors on prend 
    \[ f(x) =
      \begin{cases}
        1 & \text{si } x \in V_1,\\
        -1 & \text{si } x \in V_2.
      \end{cases}
    \]
    Soit $x \in V_1$ pour le moment, alors
    \[ (Af)(x) \sum_{y \sim x}^{} f(y) = -d = -df(x).\]
    Symétriquement, on a la même chose si $x \in V_2$. Ainsi on conclut que 
    \[ Af = -df. \]

    La réciproque ($-d$ valeur propre implique $X$ est biparti) est un exercice.

    Soit encore $X$ biparti et soit $\lambda \in \sigma(\lambda)$, soit $g$ une \index{fonction propre }fonction propre associée à
    $\lambda$ ($Ag = \lambda g$) et considérons 
    \[ f(x) = \begin{cases}
        g(x) & \text{si } x \in V_1,\\
        -g(x)& \text{si } x \in V_2.
      \end{cases} \]
    Vérifions que $Af = -\lambda f$. Soit $x \in V_1$. Alors 
    \[ (Af)(x) = \sum_{y \sim x}^{} f(\underbrace{y}_{\in V_2}) = -\sum_{y \sim x}^{} g(y) = -(Ag)(x) =
      -\lambda g(x) = -\lambda f(x).\]
    Si $x \in V_2$, on a la même conclusion. Ainsi on a bien 
    \[ Af = -\lambda f. \]
  \end{enumerate}
\end{preuve}


Soit $X$ un graphe fini connexe $d$-régulier à $n$ sommets. On range les valeurs propres de $A$ par ordre
décroissant, en tenant compte des multiplicités. On note la plus grande valeur propre $\mu_0 = d$ et on a
(puisque $d$ est de multiplicité $1$) 
\[ \mu_0 = d > \mu_1 \geq \mu_2 \geq \cdots \geq \mu_{n-1} (\geq -d). \]
Le \emph{\index{trou spectral}trou spectral} du graphe est 
\[ d - \mu_1. \]

\begin{defi}
  Un graphe $d$-régulier connexe fini est \emph{\index{graphe!de \textsc{Ramanujan}}de \textsc{Ramanujan}} si 
  \[ \mu_1 \leq 2 \sqrt{d - 1}. \]
\end{defi}

MAUVAISE DÉFINITION~! LA BONNE DÉFINITION EST LA DÉFINITION \ref{defi:graphe-de-ramanujan}.


\begin{exs}
  \begin{enumerate}
  \item Pour $d = 2$~: les graphes $2$-réguliers connexes finis sont les cycles. L'inégalité $\mu_1 \leq 2$
    est triviale.
  \item Le \index{graphe!complet}graphe complet $K_n$ sur $n$ sommets (i.e. tout sommet est relié avec tout
    autre) est $(n-1)$-régulier. Soit $J_n$ la matrice $n \times n$ remplie de $1$. Ainsi 
    \[ A = J_n - \un_n, \]
    on a de plus 
    \[ J_n = n J_n \implies \left(\frac{J_n}{n}\right)^2 = \frac{J_n}{n}. \]
    Ainsi la matrice $\frac{J_n}{n}$ est une matrice de projection, donc $\sigma\left( \frac{J_n}{n} \right) =
    \{0,1\}$. Ainsi $\sigma(J_n) = \{0,n\}$. Ainsi on en déduit que 
    \[ \sigma(A) = \left\{-1, n-1\right\} \]
    et $-1 = \mu_1$.
  \end{enumerate}
\end{exs}

\paragraph{D'où sort $2\sqrt{d-1}$?}

\begin{itemize}
\item Un graphe connexe $X$ sans cycle est un \emph{\index{arbre}arbre}. Soit $T_d$ l'arbre $d$-régulier (donc
  $T_d$ est infini). Par exemple, $T_{2d}$ est le graphe de Cayley de $\mathbb{F}_d$. De plus, $T_d$ est le
  revêtement universel de tout graphe $d$-régulier connexe.

  Si $A$ est la matrice d'adjacence de $T_d$, on peut voir $A$ comme un opérateur borné sur $\ell^2(T_d)$ et
  $A = A^\ast$, et
  \[ \sigma(A) = \left[ -2 \sqrt{d-1}, 2 \sqrt{d-1} \right]. \] Ce résultat est dû à Harry \textsc{Kesten},
  1959 (une partie de sa thèse).

  
\item Soit $(X_n)_{n > 0}$ une suite de graphes $d$-réguliers, connexes, finis, $|V_n| \xrightarrow{n \to
    \infty} \infty$. L'\index{inégalité d'\textsc{Alon-Boppana}}inégalité d'\textsc{Alon-Boppana} ($\sim$ 1984) dit 
  \[ \liminf_{n \to \infty} \mu_1(X_n) \geq 2 \sqrt{d-1}. \]
\end{itemize}

On peut interpréter ceci en disant que les graphes de Ramanujan sont les graphes \og qui ont le plus grand
trou spectral possible\fg{} asymptotiquement.

Cela pose le problème de l'existence de familles infinies de graphes de Ramanujan $d$-réguliers pour $d >
2$. En 1986, A. \textsc{Lubotzky}, R. \textsc{Phillips} et P. \textsc{Sarnak} (équipe américaine) (indépendamment
G. \textsc{Margulis} pour l'équipe de Russie) ont construit des familles infinies de graphes de Ramanujan
$d$-réguliers, pour $d$ de la forme $p^{k}+1$, $p$ premier et $k \geq 1$. Pour ce faire, ils ont utilisé la
conjecture de Ramanujan (1916) en théorie des nombres qui avait été démontrée en 1974 par Pierre \textsc{Deligne}
(médaille Fields en 1978, comme \textsc{Margulis}).

\paragraph{Question:}

Pour quelles valeurs de $d$ existe-t-il des familles infinies de graphes de Ramanujan $d$-réguliers?


Bonne définition d'un graphe de Ramanujan: 
\begin{defi}
  \label{defi:graphe-de-ramanujan}
  Un graphe fini, connexe et $d$-régulier est \emph{\index{de \textsc{Ramanujan}}de \textsc{Ramanujan}} si
  pour toute valeur propre $\mu$ de $A$ , on a $|\mu| = d$ ou 
  \[ |\mu| \leq 2 \sqrt{d - 1}. \]
\end{defi}

Interprétation: on a toujours la valeur propre $\mu = d$, $\mu = -d$ est là ssi $X$ est bicolorable et les autres
valeurs propre dans le cas Ramanujan sont dans l'intervalle $\left[-2\sqrt{d-1}, 2\sqrt{d-1}\right]$.

Pour revenir à la question posée précédemment, LPS ont montré que pour $d = 1 + p^k$ ($p$ premier), il y a des
constructions \textit{explicites} de familles infinies de graphes de Ramanujan $d$-réguliers, à la fois
bicolorables et non bicolorables.

\begin{theo}[MSS, 2013]
  Pour tout $d \geq 3$, il existe des familles infinies, non explicites, de graphes de Ramanujan $d$-réguliers bicolorables.
\end{theo}

\paragraph{Problème ouvert:}

Même chose en remplaçant bicolorable par non bicolorable.

Les technique de MSS leur permettent de contrôler \og le haut du spectre\fg{} de $A$. L'hypothèse que $X$ est
biparti leur permet de contrôler également le \og bas du spectre\fg{}, puisque dans ce cas, le spectre est
symétrique.


\section{$2$-relèvements (\og $2$-lifts\fg{})}
\label{sec:2-relevements}


\begin{defi}
  Soit $X=(V,E)$ un graphe fini. Un \emph{\index{signage}signage} de $X$ est une fonction 
  \[ s \colon V \times V \to \{-1, 0, 1\} \]
  qui est symétrique (i.e. $s(x,y) = s(y,x)$) et telle que 
  \[ s(x,y) \neq 0 \iff x \sim y. \]
\end{defi}

\begin{rem}
  On peut aussi y penser comme une fonction $E \to \{\pm 1\}$.
\end{rem}

Si $s$ est un signage de $X$, la \emph{\index{matrice d'adjacence signée}matrice d'adjacence signée} 
\[ (A^{(s)})_{xy} = s(x,y) \quad (x,y \in V). \]
Ainsi en mettant le signage constante ($s(x,y) = 1$ si $x \sim y$), c'est la matrice d'adjacence usuelle.

Si $|V| = n$ et $s$ est un signage de $X$, le \emph{\index{$2$-relèvement}$2$-relèvement} de $X$ associé à $s$
est un graphe $\tilde{X}^{(s)}$ à $2n$ sommets, avec $\tilde{V} = V_1 \sqcup V_2$, où $V_1$ et $V_2$ sont des
copies de $V$.
\begin{itemize}
\item Si $xy \in E$ et $s(x,y) = 1$, soient $x_1 \in V_1$, $x_2, \in V_2$ les sommets correspondants à $x \in
  V$, et $y_1 \in V_1$, $y_2 \in V_2$ les sommets correspondants à $y \in V$. Alors on relie $x_1$ à $y_1$
  dans $V_1$ et
  $x_2$ à $y_2$ dans $V_2$.
\item Si $xy \in E$ et $s(x,y) = -1$, soient $x_1 \in V_1$, $x_2, \in V_2$ les sommets correspondants à $x \in
  V$, et $y_1 \in V_1$, $y_2 \in V_2$ les sommets correspondants à $y \in V$. Alors on relie $x_1$ à $y_2$
  dans $V_1 \times V_2$ et
  $x_2$ à $y_1$ dans $V_2 \times V_1$.
\end{itemize}

\begin{exs}
  \begin{enumerate}
  \item Si $s(x,y) = 1$ si $x \sim y$, alors $\tilde{X}^{(s)}$ est formé de deux copies de $X$ (non connexe).
  \item Si $X = C_n$, $s(x,y) = 1$ pour chaque arête sauf $1$, le graphe est connexe~: $\tilde{X}^{(s)} \simeq
    C_{2n}$ (faire le dessin pour se convaincre).
  \end{enumerate}
\end{exs}

\begin{exercice}
  \begin{enumerate}
  \item Si $X$ est $d$-régulier, alors $\tilde{X}^{(s)}$ aussi.
  \item Si $X$ est biparti, alors $\tilde{X}^{(s)}$ aussi.
  \end{enumerate}
\end{exercice}


\begin{lem}[Y. \textsc{Bilu}, N. \textsc{Linial}, 2006]
  Soit $\tilde{A}^{(s)}$ la matrice d'adjacence de $\tilde{X}^{(s)}$ (de taille $2n \times 2n$). Alors 
  \[ \sigma(\tilde{A}^{s}) = \sigma(A) \cup \sigma(A^{(s)}). \]
\end{lem}

\begin{preuve}
  Décomposons $\tilde{A}^{(s)}$ selon la $1$ère et la $2$ème copie de $V$
  \[ 
    \tilde{A}^{(s)} =
    \begin{pmatrix}
      A_1 & A_2 \\ A_2 & A_1
    \end{pmatrix}
  \]
  où $(A_1)_{xy} = 1$ ssi $x \sim y$ et $s(x,y) = 1$ et $(A_2)_{xy} = 1$ ssi $x \sim y$ et $s(x,y) = -1$.

  Alors $A = A_1 + A_2$, et $A^{(s)} = A_1 - A_2$. Si $v$ est un vecteur propre de $A$, de valeur propre
  $\mu$, $Av = \mu v$, alors 
  \[ \tilde{A}^{(s)}
    \begin{pmatrix}
      v \\ v
    \end{pmatrix} =
    \begin{pmatrix}
      A_1v + A_2 v\\ A_2v + A_1v
    \end{pmatrix} =
    \begin{pmatrix}
      Av \\ Av
    \end{pmatrix} = \mu
    \begin{pmatrix}
      v \\ v
    \end{pmatrix}
  \]
  et donc $\sigma(A) \subset \sigma(\tilde{A}^{(s)})$.

  Si $u$ est un vecteur propre de $A^{(s)}$, de valeur propre $\lambda$, $A^{(s)} \lambda = u\lambda$. Alors 
  \[ \tilde{A}^{(s)}
    \begin{pmatrix}
      u\\ - u
    \end{pmatrix}
    =
    \begin{pmatrix}
      A_1 u - A_2 u\\ A_2u - A_1 u
    \end{pmatrix}
    =
    \begin{pmatrix}
      A^{(s)} u\\ - A^{(s)}u
    \end{pmatrix}
    =
    \begin{pmatrix}
      \lambda u\\ - \lambda u
    \end{pmatrix}
    = \lambda
    \begin{pmatrix}
      u \\ -u
    \end{pmatrix}.
  \]
  et donc $\sigma(A^{(s)}) \subset \sigma(\tilde{A}^{(s)})$. Mais puisque $
  \begin{pmatrix}
    v\\v
  \end{pmatrix} \perp
  \begin{pmatrix}
    u\\ -u
  \end{pmatrix}$. Mais en comptant les multiplicités, les $\binom{v}{v}$ engendrent un sous-espace de
  dimension $n$, les $\binom{u}{-u}$ aussi (qui est orthogonal au précédent), donc on a trouvé une base de
  vecteurs propres de $\tilde{A}^{(s)}$, et il n'y a pas d'autre valeur propre.
\end{preuve}

\paragraph{Conséquence:} Si $X$ est $d$-régulier, alors $\sigma(A^{(s)}) \subset [-d, d]$.

\paragraph{Observation:} Si $X$ est $d$-régulier Ramanujan, et $s$ est un signage tel que $\sigma(A^{(s)})
\subset \left[-2\sqrt{d-1}, 2\sqrt{d-1}\right]$, alors $\tilde{X}^{(s)}$ est Ramanujan. En effet,
$\tilde{X}^{(s)}$ est connexe car la multiplicité de la valeur propre $d$ vaut $1$ et les valeurs propres
venant de $A^{(s)}$ sont toutes dans $\left[ -2 \sqrt{d-1}, 2 \sqrt{d-1}\right]$, donc (par le Lemme),
$\tilde{X}^{(s)}$ est Ramanujan.


\begin{conj}[de \textsc{Bilu-Linial}, 2006]
  Si $X$ est $d$-régulier, alors il existe un signage $s$ de $X$ avec 
  \[ \sigma(A^{(s)}) \subset \left[-2 \sqrt{d-1}, 2\sqrt{d-1}\right]. \]
\end{conj}

\begin{theo}[MSS]
  \label{theo:3}
  La conjecture de Bilu-Linial est vraie pour un graphe $d$-régulier biparti.
\end{theo}

\begin{rem}
  La conjecture est toujours ouverte pour le cas non biparti.
\end{rem}

\begin{conseq}
  Il existe des familles infinies de graphes de Ramanujan $d$-réguliers bipartis.
\end{conseq}


L'observation et le Théorème \ref{theo:3} montrent que, si $X$ est $d$-régulier, bicolorable et Ramanujan,
alors $X$ possède un signage $s$ tel que $\tilde{X}^{(s)}$ est $d$-régulier, biparti et Ramanujan. On peut
itérer. On démarre avec le graphe biparti complet $K_{d,d}$.

\section{Preuve du Théorème \ref{theo:3}}.


Soit $X$ $d$-régulier, biparti, à $n$ sommets et $m$ arêtes. Soit $s$ un signage de $X$, et $e = \{u, v\} \in
E$, on définit une matrice positive de rang $1$: $A_e^{(s)}\geq 0$. Si $s(u,v) = 1$, 
\[ (A_e^{(s)})_{xy} =
  \begin{cases}
    1 & \text{si } x, y \in \{u,v\},\\
    0 & \text{si } x \text{ ou } y \notin \{u,v\}.
  \end{cases}
\]
Si $f \colon V \to \C$, 
\[ A_e^{(s)}(f) = \left \langle f\, ,\, \delta_u + \delta_v \right \rangle(\delta_u + \delta_v).  \]
Si $s(u,v) = -1$, alors
\[ (A_e^{(s)})_{xy} =
  \begin{cases}
    1 & \text{si } x = y = u \text{ ou } x = y = v,\\
    -1 & \text{si } (x=u \text{ et } y = v) \text{ ou } (x=v \text{ et } y = u),\\
    0 & \text{si } x \notin \{u,v\} \text{ ou } y \notin \{u,v\}.
  \end{cases}
\]
On a
\[ A_e^{(s)}(f) = \left \langle f\, ,\, \delta_u - \delta_v \right \rangle(\delta_u - \delta_v).  \]
Alors 
\[ \sum_{e \in E}^{}A_e^{(s)} = A^{(s)} + d \un_n. \]

Il y a $2^m$ signages. On munit l'ensemble des $2^m$ signages de la proba uniforme (chacun de proba
$\frac{1}{2^m}$). Pour $e \in E$ fixé, on voit $s \mapsto A_e^{(s)}$ comme une variable aléatoire à valeurs
dans les matrices $\geq 0$ de rang $1$. Les variables $(A_e^{(s)})_{e \in E}$ sont indépendantes.

Le théorème 2 de MSS s'applique et dit: pour au moins une réalisation des $A_e^{(s)}$, c'àd pour au moins un
signage $s$ 
\[ \|d \un_n + A^{(s)}\| = ZM(p_{(d\un_n + A^{(s)})}) = ZM(\E p_{(d \un_n + A^{(s)})}). \]
Notons $\mu_{max}^{(s)}$ la plus grande valeur propre de $A^{(s)}$, donc $\|d \un_n + A^{(s)}\| = d +
\mu_{max}^{(s)}$. D'autre part 
\[ \left(\E[p(d \un_n + A^{(s)})]\right)(z) = \frac{1}{2^m} \sum_{s}^{} p(d \un_n + A^{(s)})(z) =
  \frac{1}{2^m} \sum_{s}^{}p_{A^{(s)}}(z-d) = \left( \E[p_{A^{(s)}}]\right)(z-d) \]

\begin{defi}
  Un \emph{\index{mariage}mariage} \og matching\fg{} dans un graphe fini est une collection d'arêtes disjointes
  telle que chaque sommet est relié à un unique autre sommet. (Note: en cours, la définition était un dessin,
  mais c'est l'idée. Apparemment, selon la suite, on n'a pas besoin de \og marier\fg{} tous les sommets)
\end{defi}

On note $p_r$ le nombre de mariages à $r$ sommets (convention, $p_0 = 1$). Le \emph{\index{polynôme de
    mariage}polynôme de mariage} de $X$ est 
\[ \mu_X(z) := \sum_{r \geq 0}^{} (-1)^r p_r z^{n - 2r} \]
où $n$ est le nombre de sommets. Noter que $r \leq \frac{n}{2}$.

\begin{prop}
  \begin{enumerate}
  \item (MSS) $\E[p_{A^{(s)}}] = \mu_X$
  \item (\textsc{Heilmann-Lieb}, 1972) Si $|X| \geq 3$, si le degré maximal de $X$ est $d$, alors le zéro
    maximal de $\mu_X$ est inférieur ou égal à $2 \sqrt{d-1}$.
  \end{enumerate}
\end{prop}

On peut à présent terminer la preuve du Théorème \ref{theo:3}: pour un certain signage, 
\begin{align*}
  d + \mu_{max}^{(s)} = ZM(p_{(d \un_n + A^{(s)})})
  &\leq ZM(\E[p_{(d\un_n + A^{(s)})}])\\
  &= d + ZM(\E[p_{A^{(s)}}]) \\
  &= d + ZM(\mu_X) & \text{par la Prop.}\\
  &\leq d + 2\sqrt{d-1} & \text{par la Prop.}
\end{align*}
Ainsi, $\mu_{max}^{(s)} \leq 2 \sqrt{d-1}$ ce qui est la conjecture de Bilu-Linial (pour $X$ biparti).

La proposition redémontre un résultat de \textsc{Godsil-Gutman} de 1980: $\mu_X$ a toutes ses racines
réelles. La raison est que, par le Lemme \ref{lem:7} 
\[ \E[p_{A^{(s)}}] = \mu[\E[A_{e_1}^{(s)}], \ldots , \E[A_{e_m}^{(s)}]] \]
est un polynôme caractéristique mixte (on a numéroté les arêtes de $1$ à $m$). Ce dernier est réel stable,
donc toutes ses racines sont réelles.

\begin{preuve}[de la Proposition]
  \begin{enumerate}
  \item On a vu que 
    \[ \det(B) := \sum_{\sigma \in Sym(n)}^{} \epsilon(\sigma) \prod_{i=1}^n B_{i \sigma(i)}.  \]
    Ainsi, 
    \[ p_{A^{(s)}} = \det(z \un_n - A^{(s)}) = \sum_{\sigma \in Sym(n)}^{} \epsilon(\sigma) \prod_{i=1}^n (z
      \un_n - A^{(s)})_{i \sigma(i)}. \]
    Pour $\sigma \in Sym(n)$ fixé, 
    \[ (z \un_n - A^{(s)})_{i \sigma(i)} =
      \begin{cases}
        z & \text{si } i = \sigma(i)\\
        -s(i, \sigma(i)) & \text{si } i \neq \sigma(i).
      \end{cases}
    \]
    Si $S$ est l'ensemble des points non fixes de $\sigma$, et $|S| = k$, alors 
    \[ \prod_{i =^1}^{n}(z \un_n - A^{(s)})_{i \sigma(i)} = z^{n-k} (-1)^k \prod_{i \in S} s(i, \sigma(i)).\]
    Notons $\pi := \sigma|_S$. On range les $\sigma$ par $k$ croissants où $k$ est le nombre de points non
    fixes. Alors 
    \[ p_{A^{(s)}}(z) = \sum_{k = 0}^{n} (-1)^k z^{n-k} \sum_{\substack{S \subset \{1, 2, \ldots , n\}\\
          |S|=k}}^{} \sum_{\substack{\pi \in Sym(S)\\\text{sans point fixe}}}^{} \epsilon(\pi) \prod_{i \in
        S} s(i, \pi(i)). \]
    Puisque cette expression est si belle, prenons l'espérance!
    
    \[ \E[p_{A^{(s)}}](z) = \sum_{k=0}^{n} (-1)^k z^{n-k} \sum_{\substack{S \subset \{1, 2, \ldots , n\}\\
          |S|=k}}^{} \sum_{\substack{\pi \in Sym(S)\\\text{sans point fixe}}}^{} \epsilon(\pi)
      \E\left(\prod_{i \in S} s(i, \pi(i))\right). \]
    Pour $i,j$ fixés, la variable aléatoire $s \mapsto s(i,j)$ est d'espérance nulle, i.e. $\E[s(i,j)] =
    0$. On a deux cas possible
    \begin{itemize}
    \item si $i \not \sim j$, $s(i,j) = 0$,
    \item si $i \sim j$, on a une chance sur deux d'avoir $s(i,j) = 1$ et $s(i,j) = -1$.
    \end{itemize}

    Les variables aléatoires $(s(i,j))_{i,j \in V}$ sont indépendantes (la valeur sur une arête n'influe pas
    sur la valeur sur une autre arête). À ce moment là, on a très envie d'utiliser l'indépendance pour
    permuter l'espérance et le produit. Mais on ne peut pas, sinon on aurait que $p_{A^{(s)}} \equiv 0$... Il
    faut donc remarquer pourquoi ce n'est pas le cas! Si $\pi$ a un cycle de longueur au moins 3, alors 
    \[ \E\left[\prod_{i \in S} s(i, \pi(i))\right] = \underbrace{\E[s(i_1, i_2)]}_{=0} \prod \ldots  \]
    (où le deuxième produit n'est pas spécifié). Ainsi, si on a un cycle de longueur au moins $3$, l'espérance
    est nulle. Il reste donc les produits de transpositions disjointes. Soit $\pi$ un tel produit. Alors 
    \[ s(i, \pi(i))s(\pi(i), i) =
      \begin{cases}
        (\pm 1)^2 = 1 & \text{si } i \sim \pi(i)\\
        0 & \text{si } i \not \sim \pi(i).
      \end{cases}
    \]
    Dans ce cas là, $\pi$ réalise un mariage parfait sur les sommets de $S$! La seule façon d'avoir 
    \[ \E\left[\prod_{i \in S} s(i, \pi(i))\right] \neq 0 \]
    (même égal à 1 dans ce cas) est que $\pi$ réalise un \emph{\index{mariage parfait}mariage parfait} de $S$
    (c'àd un mariage impliquant tous les sommets de $S$). Ceci ne peut arriver que si $|S| = k \equiv 0 \pmod
    2$.

    Enfin, si $\pi$ est un produit de transpositions disjointes de $S$, $\epsilon(\pi) = (-1)^{\frac{k}{2}}$
    (car la signature vaut $-1$ à la puissance le nombre de transpositions). Ainsi 
    \begin{align*}
      \E[p_{A^{(s)}}] &= \sum_{\substack{k = 0\\k \text{ pair}}}^{n} z^{n-k}(-1)^{k/2} p_{k/2} & \frac{k}{2} = r\\
                      &= \sum_{r = 0}^{n/2}z^{n-2r}(-1)^r p_r\\
      &= \mu_X(z),
    \end{align*}
    et on retombe sur le beau polynôme de mariage!
    \begin{exercice}
      Les zéros de $\mu_X$ sont symétriques par rapport à $0$.
    \end{exercice}

    
  \item La preuve se fait en deux pas.
    \begin{enumerate}
    \item Pour tout $u \in V$, on a 
      \begin{equation}
        \label{eq:1}
        \mu_X(z) = z\mu_{X \setminus \{u\}}(z) - \sum_{v \sim u}^{}\mu_{X \setminus \{u, v\}}(z)
      \end{equation}
      (c'est une formule de récurrence, en partant de $\mu_\emptyset = 1$). Dans $X$, on a deux types de
      mariages (ceux qui contiennent $u$, et ceux qui ne contiennent pas $u$).
      \begin{itemize}
      \item Ceux qui ne comprennent pas $u$: ils donnent un mariage (avec le même nombre d'arêtes) de $X
        \setminus \{u\}$. Cela nous donne le terme $z \mu_{X \setminus \{u\}}(z)$.
      \item Ceux qui passent par $u$ et par un unique voisin $v$ de $u$. Disons que ce mariage a $r$ arêtes,
        alors en enlevant $uv$, il reste un mariage à $r-1$ arêtes de $X \setminus \{u, v\}$.
      \end{itemize}
      Alors 
      \begin{align*}
        \sum_{r}^{}(-1)^r p_r z^{n - 2r}
        &= \sum_{r}^{} (-1)^r p_{r, X \setminus \{u\}} z^{n - 2r} + \sum_{v
          \sim u}^{} \sum_{r \geq 0}^{} (-1)^r p_{r-1, X \setminus \{u,v\}} z^{n-2r}\\
        &= z \mu_{X \setminus \{u\}}(z) - \sum_{v \sim u}^{} \sum_{r \geq 0}^{} p_{r-2, X \setminus \{u,
          v\}}z^{(n-2)-2(r-1)}\\
        &= z \mu_{X \setminus \{u\}}(z) - \sum_{v \sim u}^{} \mu_{X \setminus \{u, v\}}(z).
      \end{align*}

    \item (La dernière fois, on a utilisé la variable $z$, cette fois, la variable $x$ juste pour perturber un
      peu :-)) On a 
      \[ \mu_X(x) = x \mu_{X \setminus \{u\}}(x) - \sum_{v \sim u}^{} \mu_{X \setminus \{u, v\}}(x). \]
      On veut montrer que si $X$ est de degré maximum $d$, alors $ZM(\mu_X) \leq 2 \sqrt{d-1}$. On montre par
      récurrence sur $|Y|$, que, si $Y$ est un sous-graphe induit de $X$, si $u \in Y$ a un voisin dans $X
      \setminus Y$, alors pour tout $x > 2\sqrt{d-1}$; on a $\mu_Y(x) > 0$ et 
      \[ \frac{\mu_Y(x)}{\mu_{Y \setminus \{u\}}(x)} \geq \sqrt{d-1} \]
      (le facteur $2$ manquant n'est pas un oubli). Un \emph{\index{sous-graphe induit}sous-graphe induit}
      veut dire que si $u, v \in V(Y)$, alors $v \sim_Y u \iff u \sim_X v$, où la notation $\sim_Z$ veut dire
      \og est adjacent à dans le graphe $Z$\fg{}.

      Le pas initial se fait pour $Y = \{u\}$, alors $\mu_Y(x) = x$ et $\mu_\emptyset(x) = 1$ (par
      convention). On vérifie que pour $x > 2\sqrt{d-1}$, on a bien $\mu_Y(x) > 0$, et 
      \[ \frac{\mu_Y(x)}{\mu_{Y \setminus \{u\}}(x)}\geq \sqrt{d-1}. \]

      On passe à présent à l'étape d'induction. Soit $u \in Y$ avec un voisin dans $X \setminus \{u\}$. On
      utilisera $\deg_Y(u) \leq d-1$ (car on sait qu'il y a une arête qui n'est pas $Y$ par hypothèse). Alors 
      \[ \mu_Y(x) = x\mu_{Y \setminus \{u\}}(x) - \sum_{v \sim_Y u}^{} \mu_{Y \setminus \{u,v\}}(x), \]
      et en divisant on obtient 
      \[ \frac{\mu_Y(x)}{\mu_{Y \setminus \{u\}}(x)} = x - \sum_{v \sim_Y u}^{} \frac{\mu_{Y \setminus \{u,
            v\}}(x)}{\mu_{Y \setminus \{u\}}(x)}.  \]
      On applique l'hypothèse de récurrence à $Y \setminus \{u\}$ pour chaque $v$ avec $v \sim_Y u$, et on a
      alors 
      \[ \frac{\mu_{Y \setminus \{u\}}(x)}{\mu_{Y \setminus \{u,v\}}(x)} \geq \sqrt{d-1} \text{ si } x > 2
        \sqrt{d -1}. \]
      Donc 
      \begin{align*}
        \frac{\mu_Y(x)}{\mu_{Y \setminus \{u\}}(x)}
        &\geq x - \sum_{v \sim_Y u}^{} \frac{1}{\sqrt{d-1}} &\text{
                                                              si } x > 2 \sqrt{d-1}.\\
        &> 2\sqrt{d-1} - \sum_{v \sim_Y u}^{} \frac{1}{\sqrt{d-1}}\\
        &\geq 2 \sqrt{d-1} - \frac{d-1}{\sqrt{d-1}}\\
        &= \sqrt{d-1}.
      \end{align*}
      Comme $\mu_{Y \setminus \{u\}}(x) > 0$ par hypothèse de récurrence, on a aussi $\mu_Y(x) > 0$.
    \end{enumerate}

  \item On doit encore montrer que $\mu_X(x) > 0$ pour $x > 2 \sqrt{d-1}$ (si c'est positif à droite de cette
    valeur, tous les zéros sont à gauche). Soit $u \in X$, alors 
    \[ \mu_X(x) = \mu_{X \setminus \{u\}}(x)\left( x - \sum_{v \sim u}^{} \frac{\mu_{X \setminus
            \{u,v\}}(x)}{\mu_{X \setminus \{u\}}(x)} \right). \]
    On applique le point précédent à $Y = X \setminus \{u\}$. Alors 
    \[ \mu_{X \setminus \{u\}}(x) > 0 \]
    pour $x > 2 \sqrt{d-1}$. D'autre part, 
    \begin{align*}
      x - \sum_{v \sim u}^{} \frac{\mu_{X \setminus \{u,v\}}(x)}{\mu_{X \setminus \{u\}}(x)}
      &\geq x - \sum_{v\sim u}^{} \frac{1}{\sqrt{d-1}} \\
      &> 2 \sqrt{d-1} - \sum_{v \sim
        u}^{}\frac{1}{\sqrt{d-1}}\\
      &\geq 2 \sqrt{d-1} - \frac{d}{\sqrt{d-1}} \\
      &= \frac{2(d-1) - d}{\sqrt{d-1}} \\
      &= \frac{d - 2}{\sqrt{d - 1}}\\
        &\geq 0
    \end{align*}
    par l'hypothèse que $d \geq 2$.
  \end{enumerate}
\end{preuve}



\section{Expanseurs}
\label{sec:expanseurs}

Soit $X = (V, E)$ un graphe fini, connexe, $k$-régulier. Le \emph{\index{Laplacien}Laplacien (combinatoire)}
de $X$ est l'application linéaire 
\[ \Delta \colon \R V \to \R V, \ f \mapsto \Delta f \]
où 
\[ \Delta f(x) = k \cdot f(x) - \sum_{y \sim x}^{}f(y). \]
Si $|V| = n$, alors 
\[ \Delta = k \un_n - A \]
On a vu que le spectre de $A$ est 
\[ k = \mu_0 > \mu_1 \geq \cdots \geq \mu_{n-1} (\geq -k). \]
Le spectre de $\Delta$ est 
\[ 0 = \lambda_0 < \lambda_1 = k - \mu_1 \leq \lambda_2 = k - \mu_2 \leq \cdots \leq \lambda_{n-1} = k -
  \mu_{n-1} (\leq 2k). \]
On a 
\[ \Delta f = 0 \iff kf = Af \iff \forall x \in V\ \colon \ kf(x) = \sum_{y \sim x}^{}f(y) \iff f(x) =
  \frac{1}{k} \sum_{y \sim x}^{} f(y) \]
(une fonction est harmonique ssi elle satisfait la propriété de la moyenne, c'àd qu'elle est égale à sa
moyenne sur les voisins). On a vu que $\R V$ est l'ensemble des fonctions sur $V$ et $\R E$ est l'ensemble des
fonctions sur $E$. Choisissons une orientation de $X$, c'àd pour chaque arête, on choisit l'origine $e^-$ et
l'extrémité $e^+$. Grâce à ça, on a 
\[ d\colon \R V \to \R E,\ f \mapsto df \]
la \emph{\index{différentielle}différentielle} (ou \emph{\index{opérateur de cobord}opérateur de cobord} ou
\emph{\index{opérateur aux différences}opérateur aux différences}) où 
\[ d f(e) = f(e^+) - f(e^-). \]
On voit facilement que 
\[ df \equiv 0 \iff f \text{ est constante.} \]

Pour $v$ un sommet, on note $e^+ = v$ les arêtes entrantes et $e^- = v$ les arêtes sortantes. On va définir la
transposée de $d$ dans la proposition suivante.

\begin{prop}
  \begin{enumerate}
  \item $d^t \colon \R E \to \R V$, $\xi \mapsto d^t \xi$ où
    \[d^t \xi (v) = \sum_{e: e^+ = v}^{} \xi(e) - \sum_{e: e^- = v}^{} \xi(e).\]
    
  \item $\Delta = d^td$ (donc le Laplacien est indépendant de l'orientation).
  \end{enumerate}
\end{prop}


\begin{rem}
  Si on regarde \[\ker d^t = \left\{ \xi \in \R E \colon d^t \xi \equiv 0 \right\} = \left\{ \xi\ \colon\
    \forall v \in V\ \sum_{e: e^+ = v}^{}\xi(e) - \sum_{e: e^- = v}^{}\xi(e) = 0 \right\},\] c'est exactement
  la \index{première loi de Kirchoff}première loi de Kirchoff. Ainsi $\ker d^t$ est l'espace des
  \emph{\index{flots}flots} sur $X$.
\end{rem}

\begin{preuve}
  \begin{enumerate}
  \item $d^t$ défini par, pour tout $f \in \R V$ et $\xi \in \R E$, alors 
    \[ \left \langle d^t \xi\, ,\, f \right \rangle_V = \left \langle \xi\, ,\, d f \right \rangle_E. \]
    On a 
    \[ \left \langle f\, ,\, g \right \rangle_V := \sum_{v \in V}^{}f(v)g(v) \text{ et } \left \langle \xi\,
        ,\, \eta \right \rangle_E := \sum_{e \in E}^{} \xi(e)\eta(e). \]
    Ainsi 
    \begin{align*}
      \left \langle \sum_{e:e^+ = v}^{} \xi(e) - \sum_{e:e^- = v}^{} \xi(e)\, ,\, f \right
      \rangle_V
      &= \sum_{v \in V}^{} \left( \sum_{e^+=v}^{} \xi(e) \right)f(v) - \sum_{v \in V}^{} \left(\sum_{e^- =
        v}^{} \xi(e)\right)f(v)\\
      &= \sum_{e \in E}^{} \xi(e) \underbrace{\sum_{v: e^+ = v}^{} f(v)}_{=f(e^+)} - \sum_{e \in E}^{} \xi(e)
        \underbrace{\sum_{v: e^- = v}^{}f(v)}_{=f(e^-)}\\
      &= \sum_{e \in E}^{} \xi(e)\left( f(e^+) - f(e^-) \right)\\
      &= \sum_{e \in E}^{} \xi(e) df(e)\\
      &= \left \langle \xi\, ,\, df \right \rangle.
    \end{align*}

    
  \item On a 
    \begin{align*}
      (d^td)(f)(v) = d^t(df)(v)
      &= \sum_{e: e^+ = v}^{} df(e) - \sum_{e: e^- = v}^{} df(e)\\
      &= \sum_{e: e^+ = v}^{}(f(e^+) - f(e^-)) - \sum_{e: e^- = v}^{}(f(e^+) - f(e^-))\\
      &= \sum_{e: e^+ = v}^{}(f(v) - f(e^-)) + \sum_{e: e^- = v}^{}(f(v) - f(e^+))\\
      &= k f(v) - \sum_{w \sim v}^{} f(w)\\
      &= \Delta f(v)
    \end{align*}
    où l'avant-dernière égalité suit du fait qu'on a $k$ voisins de $v$ et qu'on les compte tous.
  \end{enumerate}
\end{preuve}

\begin{exercice}[\index{quotient de \emph{Rayleigh}}quotient de \emph{Rayleigh}]
  On a 
  \[ \lambda_1 = \min\{\frac{\|df\|^2}{\|f\|^2},\ f \in \R V,\ f \neq 0,\ f \perp 1\} \]
    où $f \perp 1$ signifie $\sum_{v \in V}^{} f(v) = 0$.
\end{exercice}


\paragraph{Interprétation du trou spectral}

Soit $A \subset V$. Le \emph{\index{bord de $A$}bord de $A$}, noté $\partial A$ est l'ensemble des arêtes
reliant $A$ à $V \setminus A$. C'est donc les arêtes qu'il faut enlever pour déconnecter $A$ de $V \setminus
A$. Ainsi $\partial A = \partial (V \setminus A)$.

\begin{defi}
  La \emph{\index{constante isopérimétrique}constante isopérimétrique}, ou \emph{\index{constante de
      \textsc{Cheeger}}constante de \textsc{Cheeger}} de $X$ est 
  \[ h(X) = \min_{0 \neq |A| \leq \frac{|V|}{2}} \frac{|\partial A|}{|A|} \]
\end{defi}

La constante $h$ mesure la difficulté à déconnecter $X$, c'àd la robustesse de $X$ vu comme réseau de
communication.

\begin{ex}
  \begin{enumerate}
  \item Si $X = C_n$ est un cycle de longueur $n$, prenons $A$ un demi-cycle. Alors $|\partial A| = 2$, et
    $|A| \sim \frac{n}{2}$. Alors 
    \[ h(X) \leq \frac{2}{\frac{n}{2}} = \frac{4}{n} \xrightarrow{n \to \infty} 0. \]
    
  \item Si $X = K_n$ est le graphe complet sur $n$ sommets, alors $|\partial A| = |A|(n - |A|)$. Donc 
    \[ h(X) = \min_{|A| \leq \frac{n}{2}} \frac{|A|(n - |A|)}{|A|} \sim \frac{n}{2}.  \]
  \end{enumerate}
\end{ex}























%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../MAeZP_cours.tex" 
%%% End: